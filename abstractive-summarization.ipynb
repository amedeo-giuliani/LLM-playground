{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datasets import load_dataset\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\nimport evaluate\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:08:47.777173Z","iopub.execute_input":"2025-10-25T18:08:47.777488Z","iopub.status.idle":"2025-10-25T18:09:14.600285Z","shell.execute_reply.started":"2025-10-25T18:08:47.777465Z","shell.execute_reply":"2025-10-25T18:09:14.599507Z"}},"outputs":[{"name":"stderr","text":"2025-10-25 18:08:59.518896: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761415739.709935      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761415739.764706      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Abstractive summarization with Flan T5 Small","metadata":{}},{"cell_type":"markdown","source":"## Load and inspect dataset","metadata":{}},{"cell_type":"code","source":"datasets = load_dataset(\"knkarthick/xsum\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:09:14.601404Z","iopub.execute_input":"2025-10-25T18:09:14.601936Z","iopub.status.idle":"2025-10-25T18:09:33.032163Z","shell.execute_reply.started":"2025-10-25T18:09:14.601898Z","shell.execute_reply":"2025-10-25T18:09:33.031468Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f69460be8e32442ca1766211d1a6fa32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.csv:   0%|          | 0.00/480M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b779f2085e73409e919ab945b01af351"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation.csv:   0%|          | 0.00/26.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd97900f4af44a55bcc1b7d85c4af576"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.csv:   0%|          | 0.00/26.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c38f2b9081954b1784c6275beae861fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/204045 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1bce6e552844d4fb296eec2c59d44b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/11332 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0093046e7ebd4768bf2e08d72338433e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11334 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"999804e1134748028692a8644eaf9318"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:09:33.032823Z","iopub.execute_input":"2025-10-25T18:09:33.033033Z","iopub.status.idle":"2025-10-25T18:09:33.038177Z","shell.execute_reply.started":"2025-10-25T18:09:33.033017Z","shell.execute_reply":"2025-10-25T18:09:33.037504Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 204045\n    })\n    validation: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 11332\n    })\n    test: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 11334\n    })\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"datasets[\"train\"] = datasets[\"train\"].select(range(10000))\ndatasets[\"validation\"] = datasets[\"validation\"].select(range(1000))\ndatasets[\"test\"] = datasets[\"test\"].select(range(1000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:09:48.039674Z","iopub.execute_input":"2025-10-25T18:09:48.040127Z","iopub.status.idle":"2025-10-25T18:09:48.050840Z","shell.execute_reply.started":"2025-10-25T18:09:48.040104Z","shell.execute_reply":"2025-10-25T18:09:48.050215Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:09:48.052143Z","iopub.execute_input":"2025-10-25T18:09:48.052410Z","iopub.status.idle":"2025-10-25T18:09:48.591532Z","shell.execute_reply.started":"2025-10-25T18:09:48.052392Z","shell.execute_reply":"2025-10-25T18:09:48.590635Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 10000\n    })\n    validation: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 1000\n    })\n    test: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Preprocess data","metadata":{}},{"cell_type":"code","source":"datasets = datasets.filter(lambda x: x[\"dialogue\"] is not None and len(x[\"dialogue\"].strip()) > 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:09:48.592296Z","iopub.execute_input":"2025-10-25T18:09:48.592549Z","iopub.status.idle":"2025-10-25T18:09:48.715998Z","shell.execute_reply.started":"2025-10-25T18:09:48.592530Z","shell.execute_reply":"2025-10-25T18:09:48.715168Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75ae55a23253435b90b4be1e81c3512f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00f869cf5dad49b0a7c630d8c42a2bcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c4b8d61541e45ceb4fafd209188653a"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"checkpoint = \"google/flan-t5-small\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:09:48.717717Z","iopub.execute_input":"2025-10-25T18:09:48.718207Z","iopub.status.idle":"2025-10-25T18:09:51.314221Z","shell.execute_reply.started":"2025-10-25T18:09:48.718187Z","shell.execute_reply":"2025-10-25T18:09:51.313400Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acad59c87fde488487aafbba577c0622"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a9d5f7caa7542f5825c45b14cc0694a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"941a888de96240f1abc2c0db196f5062"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac6c520487a74f3691ece4ca0702e95f"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"max_input_length = 512\nmax_target_length = 150\n\ndef preprocess(example):\n    inputs = [\"summarize: \" + doc for doc in example[\"dialogue\"]]  # with flan-t5 we need to instruct it with the task\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n    labels = tokenizer(text_target=example[\"summary\"], max_length=max_target_length, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_datasets = datasets.map(preprocess, batched=True, remove_columns=datasets[\"train\"].column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:09:51.315092Z","iopub.execute_input":"2025-10-25T18:09:51.315366Z","iopub.status.idle":"2025-10-25T18:10:00.334952Z","shell.execute_reply.started":"2025-10-25T18:09:51.315344Z","shell.execute_reply":"2025-10-25T18:10:00.334131Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9998 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1acd67f97e204c50a99292bc20316fd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/999 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ca8c3c577d94c1290d4067a1c74dfe0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"890e73b67cfc4ccda5f66a1386566bba"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"tokenized_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:10:00.335774Z","iopub.execute_input":"2025-10-25T18:10:00.336053Z","iopub.status.idle":"2025-10-25T18:10:00.340544Z","shell.execute_reply.started":"2025-10-25T18:10:00.336036Z","shell.execute_reply":"2025-10-25T18:10:00.340004Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 9998\n    })\n    validation: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 999\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"## Load model","metadata":{}},{"cell_type":"code","source":"checkpoint = \"google/flan-t5-small\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:10:00.341206Z","iopub.execute_input":"2025-10-25T18:10:00.341468Z","iopub.status.idle":"2025-10-25T18:10:05.121208Z","shell.execute_reply.started":"2025-10-25T18:10:00.341445Z","shell.execute_reply":"2025-10-25T18:10:05.120578Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15ab757dc8814c23b6a438eacc1b79bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"272b27bbddac4b38bd5277e84f9d83b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57aedfbfeb2d41099b39f0d36c2da47b"}},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"## Fine tune model","metadata":{}},{"cell_type":"code","source":"import nltk\n\nnltk.download(\"punkt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:10:05.121912Z","iopub.execute_input":"2025-10-25T18:10:05.122131Z","iopub.status.idle":"2025-10-25T18:10:05.705501Z","shell.execute_reply.started":"2025-10-25T18:10:05.122116Z","shell.execute_reply":"2025-10-25T18:10:05.704657Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"from nltk.tokenize import sent_tokenize\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\nrouge_score = evaluate.load(\"rouge\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    # Decode generated summaries into text\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    # Decode reference summaries into text\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    # ROUGE expects a newline after each sentence\n    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n    # Compute ROUGE scores\n    result = rouge_score.compute(\n        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n    )\n    result = {key: value * 100 for key, value in result.items()}  # Convert to percentage\n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:10:05.706335Z","iopub.execute_input":"2025-10-25T18:10:05.706608Z","iopub.status.idle":"2025-10-25T18:10:07.449215Z","shell.execute_reply.started":"2025-10-25T18:10:05.706592Z","shell.execute_reply":"2025-10-25T18:10:07.448622Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40428ec2e3894ba5b0910d31575eb107"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\nbatch_size = 8\nlogging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n\n# training_args = Seq2SeqTrainingArguments(\n#     output_dir=\"./flan-t5-xsum\",\n#     eval_strategy=\"epoch\",\n#     learning_rate=2e-4,\n#     per_device_train_batch_size=batch_size,\n#     per_device_eval_batch_size=batch_size,\n#     weight_decay=0.01,\n#     save_total_limit=2,\n#     num_train_epochs=3,\n#     predict_with_generate=True,\n#     # fp16=True,\n#     logging_steps=logging_steps,\n#     push_to_hub=False,\n#     report_to=\"none\"\n# )\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./flan-t5-xsum\",\n    eval_strategy=\"epoch\",\n    learning_rate=5e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=3,\n    predict_with_generate=True,\n    logging_steps=logging_steps,\n    push_to_hub=False,\n    report_to=\"none\"\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\n# trainer.train(resume_from_checkpoint = True)\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:10:41.689588Z","iopub.execute_input":"2025-10-25T18:10:41.690133Z","iopub.status.idle":"2025-10-25T18:36:25.461547Z","shell.execute_reply.started":"2025-10-25T18:10:41.690108Z","shell.execute_reply":"2025-10-25T18:36:25.460830Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_37/183533910.py:38: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6250/6250 25:43, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.606800</td>\n      <td>2.309609</td>\n      <td>29.722700</td>\n      <td>8.744100</td>\n      <td>23.735800</td>\n      <td>23.698800</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.539700</td>\n      <td>2.301565</td>\n      <td>29.976500</td>\n      <td>8.954200</td>\n      <td>23.859600</td>\n      <td>23.833700</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.491800</td>\n      <td>2.297836</td>\n      <td>30.097500</td>\n      <td>9.057700</td>\n      <td>24.002700</td>\n      <td>23.972400</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.454000</td>\n      <td>2.297060</td>\n      <td>30.150400</td>\n      <td>8.879900</td>\n      <td>23.971100</td>\n      <td>23.938900</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.433000</td>\n      <td>2.295445</td>\n      <td>29.860400</td>\n      <td>8.772000</td>\n      <td>23.878800</td>\n      <td>23.856400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=6250, training_loss=2.5051662254333498, metrics={'train_runtime': 1543.2517, 'train_samples_per_second': 32.393, 'train_steps_per_second': 4.05, 'total_flos': 9271959870652416.0, 'train_loss': 2.5051662254333498, 'epoch': 5.0})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"from transformers import pipeline\nsummarizer = pipeline(\"text2text-generation\",\n                      model=\"/kaggle/working/flan-t5-xsum/checkpoint-6250\",\n                      max_length=100,\n                      min_length=50,)\nsummarizer_base = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:45:38.542327Z","iopub.execute_input":"2025-10-25T18:45:38.543086Z","iopub.status.idle":"2025-10-25T18:45:40.097003Z","shell.execute_reply.started":"2025-10-25T18:45:38.543060Z","shell.execute_reply":"2025-10-25T18:45:40.095969Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\nDevice set to use cuda:0\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"def print_summary(idx):\n    dialogue = datasets[\"test\"][idx][\"dialogue\"]\n    ref_summary = datasets[\"test\"][idx][\"summary\"]\n    summary = summarizer(\"summarize: \"+datasets[\"test\"][idx][\"dialogue\"])[0][\"generated_text\"]\n    baseline = summarizer_base(\"summarize: \"+datasets[\"test\"][idx][\"dialogue\"])[0][\"generated_text\"]\n    print(f\"'>>> Dialogue: {dialogue}'\")\n    print(f\"\\n'>>> Summary: {summary}'\")\n    print(f\"\\n'>>> Reference summary: {ref_summary}'\")\n    print(f\"\\n'>>> Baseline (no fine tuning): {baseline}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:45:41.390444Z","iopub.execute_input":"2025-10-25T18:45:41.390730Z","iopub.status.idle":"2025-10-25T18:45:41.395716Z","shell.execute_reply.started":"2025-10-25T18:45:41.390711Z","shell.execute_reply":"2025-10-25T18:45:41.394914Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"print_summary(100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:49:39.342195Z","iopub.execute_input":"2025-10-25T18:49:39.342786Z","iopub.status.idle":"2025-10-25T18:49:40.935977Z","shell.execute_reply.started":"2025-10-25T18:49:39.342764Z","shell.execute_reply":"2025-10-25T18:49:40.935184Z"}},"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\nToken indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"'>>> Dialogue: The British Transport Police said the move was a \"proportionate response\" in the face of a mounting terrorism threat.\nSpecially trained officers will begin carrying the stun weapons over the next few weeks.\nIt brings the Scottish force into line with their counterpart in England, where Tasers have been used since 2011.\nThe weapons are used to incapacitate suspects through the use of an electric current.\nTemporary Assistant Chief Constable Alun Thomas said: \"This decision is not based on specific intelligence of any criminal behaviour or imminent threat, but will allow us the option to deploy Taser devices where, in the course of their duty, an officer needs to protect the public or themselves by using force.\n\"The current threat to the UK from international terrorism remains 'severe', meaning an attack is highly likely.\n\"Recent terrorist attacks across the world are a stark reminder that the threat from terrorism is a genuine risk, and it is important that we keep our security measures and operational tactics under constant review.\"\nOfficers south of the border fired the Tasers eight times during 2015, according to a reply to recent Freedom of Information request to the force.\nIn one instance, police used a weapon against a man armed with a large knife - a move which \"undoubtedly\" prevented people from being hurt, according to Mr Thomas.\nHe said: \"In our assessment, the introduction of Taser devices in Scotland is a proportionate response and provides an additional option for our officers to consider when confronted with a genuine threat to themselves or the public.\n\"By way of example, in December last year, police deployed a Taser device against a man armed with a large bladed knife, preventing him cutting the throat of stranger who he had targeted at random at Leytonstone station, east London.\n\"Undoubtedly the use of the Taser device in this incident prevented even further harm to the travelling public.\"\n\"We believe that the public in Scotland deserve the same level of protection as people elsewhere on the rail network.\"\nBritish Transport Police said they reached the decision on Tasers following \"detailed discussions\" with Police Scotland.\nScottish Ministers have also been briefed.\nThe force refused to reveal how many officers would receive the training required to carry Tasers \"for security reasons\".\nCh Supt John McBride, divisional commander for the Scotland, said Taser use by officers would be monitored.\n\"Every time we unholster it, it will be subject to review,\" he told the BBC's Good Morning Scotland programme.\n\"It will be subject to internal review by our own specialists, but also we have agreed with the Police Investigations and Review Commissioner that where there is a discharge and serious incidents involving Taser then we will refer ourselves to the Pirc for them to review the circumstances of the case and if necessary carry out an investigation.\"'\n\n'>>> Summary: Police in Scotland are to deploy a Taser device in the face of a \"severe threat\" to the public, a police chief has told the BBC's Good Morning Scotland programme on Wednesday night. \"We believe that the public in Scotland deserve the same level of protection as people elsewhere on the rail network,\" the chief constable has told the BBC.'\n\n'>>> Reference summary: Officers who police Scotland's railways are to be armed with Tasers in a bid to increase security on the network.'\n\n'>>> Baseline (no fine tuning): Scotland's police force is to deploy Taser devices in response to a threat to the public, it has been announced.'\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"## Rouge SEM scoring","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/zhangming-19/ROUGE-SEM.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T19:00:26.529623Z","iopub.execute_input":"2025-10-25T19:00:26.530390Z","iopub.status.idle":"2025-10-25T19:00:27.484285Z","shell.execute_reply.started":"2025-10-25T19:00:26.530347Z","shell.execute_reply":"2025-10-25T19:00:27.483555Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'ROUGE-SEM'...\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"remote: Enumerating objects: 63, done.\u001b[K\nremote: Counting objects: 100% (63/63), done.\u001b[K\nremote: Compressing objects: 100% (35/35), done.\u001b[K\nremote: Total 63 (delta 17), reused 47 (delta 12), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (63/63), 18.54 KiB | 9.27 MiB/s, done.\nResolving deltas: 100% (17/17), done.\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"!git clone https://github.com/summanlp/evaluation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:50:24.228528Z","iopub.execute_input":"2025-10-25T18:50:24.229080Z","iopub.status.idle":"2025-10-25T18:50:25.705760Z","shell.execute_reply.started":"2025-10-25T18:50:24.229058Z","shell.execute_reply":"2025-10-25T18:50:25.704692Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'evaluation'...\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"remote: Enumerating objects: 2075, done.\u001b[K\nremote: Total 2075 (delta 0), reused 0 (delta 0), pack-reused 2075 (from 1)\u001b[K\nReceiving objects: 100% (2075/2075), 6.65 MiB | 22.46 MiB/s, done.\nResolving deltas: 100% (360/360), done.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"!export ROUGE_EVAL_HOME=\"/kaggle/working/evaluation/ROUGE-RELEASE-1.5.5/data/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:53:01.764642Z","iopub.execute_input":"2025-10-25T18:53:01.765294Z","iopub.status.idle":"2025-10-25T18:53:01.935839Z","shell.execute_reply.started":"2025-10-25T18:53:01.765265Z","shell.execute_reply":"2025-10-25T18:53:01.934882Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"!pyrouge_set_rouge_path /kaggle/working/evaluation/ROUGE-RELEASE-1.5.5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:53:09.180283Z","iopub.execute_input":"2025-10-25T18:53:09.180641Z","iopub.status.idle":"2025-10-25T18:53:09.479761Z","shell.execute_reply.started":"2025-10-25T18:53:09.180614Z","shell.execute_reply":"2025-10-25T18:53:09.478788Z"}},"outputs":[{"name":"stdout","text":"2025-10-25 18:53:09,357 [MainThread  ] [INFO ]  Set ROUGE home directory to /kaggle/working/evaluation/ROUGE-RELEASE-1.5.5.\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"def get_summaries(indexes):\n    for idx in indexes:\n        dialogue = datasets[\"test\"][idx][\"dialogue\"]\n        ref_summary = datasets[\"test\"][idx][\"summary\"]\n        summary = summarizer(\"summarize: \"+datasets[\"test\"][idx][\"dialogue\"])[0][\"generated_text\"]\n        # baseline = summarizer_base(\"summarize: \"+datasets[\"test\"][idx][\"dialogue\"])[0][\"generated_text\"]\n\n        with open(\"./candidate.txt\", \"a\") as text_file:\n            text_file.write(summary)\n\n        with open(\"./reference.txt\", \"a\") as text_file:\n            text_file.write(ref_summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T19:54:17.597765Z","iopub.execute_input":"2025-10-25T19:54:17.598442Z","iopub.status.idle":"2025-10-25T19:54:17.603981Z","shell.execute_reply.started":"2025-10-25T19:54:17.598417Z","shell.execute_reply":"2025-10-25T19:54:17.603284Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"!rm candidate.txt\n!rm reference.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T20:02:34.692866Z","iopub.execute_input":"2025-10-25T20:02:34.693624Z","iopub.status.idle":"2025-10-25T20:02:35.031226Z","shell.execute_reply.started":"2025-10-25T20:02:34.693588Z","shell.execute_reply":"2025-10-25T20:02:35.030143Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":88},{"cell_type":"code","source":"get_summaries([idx for idx in range(0,5)])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T20:02:37.160870Z","iopub.execute_input":"2025-10-25T20:02:37.161230Z","iopub.status.idle":"2025-10-25T20:02:41.465152Z","shell.execute_reply.started":"2025-10-25T20:02:37.161205Z","shell.execute_reply":"2025-10-25T20:02:41.464524Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"!cat reference.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T20:02:57.106606Z","iopub.execute_input":"2025-10-25T20:02:57.106900Z","iopub.status.idle":"2025-10-25T20:02:57.281018Z","shell.execute_reply.started":"2025-10-25T20:02:57.106877Z","shell.execute_reply":"2025-10-25T20:02:57.280059Z"}},"outputs":[{"name":"stdout","text":"There is a \"chronic\" need for more housing for prison leavers in Wales, according to a charity.\nA man has appeared in court after firearms, ammunition and cash were seized by police in Edinburgh.\nFour people accused of kidnapping and torturing a mentally disabled man in a \"racially motivated\" attack streamed on Facebook have been denied bail.\nWest Brom have appointed Nicky Hammond as technical director, ending his 20-year association with Reading.\nThe pancreas can be triggered to regenerate itself through a type of fasting diet, say US researchers.\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":91},{"cell_type":"code","source":"!cat candidate.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T20:02:41.466194Z","iopub.execute_input":"2025-10-25T20:02:41.466455Z","iopub.status.idle":"2025-10-25T20:02:41.640293Z","shell.execute_reply.started":"2025-10-25T20:02:41.466428Z","shell.execute_reply":"2025-10-25T20:02:41.639223Z"}},"outputs":[{"name":"stdout","text":"A charity has said it is \"a desperate need\" to find suitable accommodation for those leaving prison, a charity has said, in a bid to save the public purse of more than a hundred pounds a week, in the wake of changes to the Housing Act in Wales.\nA man has appeared in court charged with the murder of a man in Edinburgh in connection with a shooting at a house in the city of Edinburgh, a police investigation has concluded...''Another man has appeared in court charged with the murder of a man in Edinburgh, a police investigation has concluded.\nFour people have been charged with aggravated kidnapping and battery after a man allegedly beat a white man in a van in Chicago, a court has heard, according to a police investigation into the incident.\nWest Brom have signed West Brom striker David O'Neill on a two-year deal... CLICK HERE for all the latest football news from West Brom news, including football news, football news, football news and football news from West Brom.\nPeople with type 1 and type 2 diabetes should not rush off and crash diet, according to a new study by the University of California, which found that the diet regenerated a special type of cell in the pancreas.\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"!python3 /kaggle/working/ROUGE-SEM/calculate_lexical_similarity.py -r reference.txt -c candidate.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T20:10:05.972323Z","iopub.execute_input":"2025-10-25T20:10:05.973029Z","iopub.status.idle":"2025-10-25T20:10:13.359079Z","shell.execute_reply.started":"2025-10-25T20:10:05.973004Z","shell.execute_reply":"2025-10-25T20:10:13.358222Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n################### Total #################\nRouge\nROUGE 1-2-L F: 28.00-11.97-28.58-\n################### Each #################\nROUGE 1-2-L F: 36.92- 9.52-31.62-\nROUGE 1-2-L F: 25.71-17.65-32.89-\nROUGE 1-2-L F: 34.48-17.86-34.29-\nROUGE 1-2-L F: 14.29- 7.41-20.02-\nROUGE 1-2-L F: 28.57- 7.41-24.06-\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"lex_sim = pd.read_csv(\"/kaggle/working/lexical_similarity.csv\")\nlex_sim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T20:10:58.992633Z","iopub.execute_input":"2025-10-25T20:10:58.993503Z","iopub.status.idle":"2025-10-25T20:10:59.026389Z","shell.execute_reply.started":"2025-10-25T20:10:58.993472Z","shell.execute_reply":"2025-10-25T20:10:59.025754Z"}},"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                                ref  \\\n0           0  there is a \"chronic\" need for more housing for...   \n1           1  a man has appeared in court after firearms, am...   \n2           2  four people accused of kidnapping and torturin...   \n3           3  west brom have appointed nicky hammond as tech...   \n4           4  the pancreas can be triggered to regenerate it...   \n\n                                                 can     R1     R2     RL  \\\n0  a charity has said it is \"a desperate need\" to...  36.92   9.52  31.62   \n1  a man has appeared in court charged with the m...  25.71  17.65  32.89   \n2  four people have been charged with aggravated ...  34.48  17.86  34.29   \n3  west brom have signed west brom striker david ...  14.29   7.41  20.02   \n4  people with type 1 and type 2 diabetes should ...  28.57   7.41  24.06   \n\n   lex_score  \n0     26.580  \n1     26.164  \n2     29.418  \n3     14.518  \n4     20.418  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>ref</th>\n      <th>can</th>\n      <th>R1</th>\n      <th>R2</th>\n      <th>RL</th>\n      <th>lex_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>there is a \"chronic\" need for more housing for...</td>\n      <td>a charity has said it is \"a desperate need\" to...</td>\n      <td>36.92</td>\n      <td>9.52</td>\n      <td>31.62</td>\n      <td>26.580</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>a man has appeared in court after firearms, am...</td>\n      <td>a man has appeared in court charged with the m...</td>\n      <td>25.71</td>\n      <td>17.65</td>\n      <td>32.89</td>\n      <td>26.164</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>four people accused of kidnapping and torturin...</td>\n      <td>four people have been charged with aggravated ...</td>\n      <td>34.48</td>\n      <td>17.86</td>\n      <td>34.29</td>\n      <td>29.418</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>west brom have appointed nicky hammond as tech...</td>\n      <td>west brom have signed west brom striker david ...</td>\n      <td>14.29</td>\n      <td>7.41</td>\n      <td>20.02</td>\n      <td>14.518</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>the pancreas can be triggered to regenerate it...</td>\n      <td>people with type 1 and type 2 diabetes should ...</td>\n      <td>28.57</td>\n      <td>7.41</td>\n      <td>24.06</td>\n      <td>20.418</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":97},{"cell_type":"code","source":"!cp -r /kaggle/working/flan-t5-xsum/checkpoint-6250/* /kaggle/working/ROUGE-SEM/model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T20:17:16.390456Z","iopub.execute_input":"2025-10-25T20:17:16.391137Z","iopub.status.idle":"2025-10-25T20:17:17.360885Z","shell.execute_reply.started":"2025-10-25T20:17:16.391108Z","shell.execute_reply":"2025-10-25T20:17:17.360145Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":105},{"cell_type":"code","source":"!python3 /kaggle/working/ROUGE-SEM/calculate_semantic_similarity.py -r reference.txt -c candidate.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T20:27:43.000899Z","iopub.execute_input":"2025-10-25T20:27:43.001600Z","iopub.status.idle":"2025-10-25T20:27:53.612116Z","shell.execute_reply.started":"2025-10-25T20:27:43.001575Z","shell.execute_reply":"2025-10-25T20:27:53.611250Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"2025-10-25 20:27:48.438026: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761424068.460485     591 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761424068.467241     591 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n100%|██████████████████████████████████████████| 5/5 [00:00<00:00, 10225.02it/s]\n","output_type":"stream"}],"execution_count":119},{"cell_type":"code","source":"sem_sim = pd.read_csv(\"/kaggle/working/semantic_similarity.csv\")\nsem_sim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T20:28:35.370447Z","iopub.execute_input":"2025-10-25T20:28:35.371119Z","iopub.status.idle":"2025-10-25T20:28:35.383795Z","shell.execute_reply.started":"2025-10-25T20:28:35.371089Z","shell.execute_reply":"2025-10-25T20:28:35.383232Z"}},"outputs":[{"execution_count":120,"output_type":"execute_result","data":{"text/plain":"                                                 ref  \\\n0  there is a \"chronic\" need for more housing for...   \n1  a man has appeared in court after firearms, am...   \n2  four people accused of kidnapping and torturin...   \n3  west brom have appointed nicky hammond as tech...   \n4  the pancreas can be triggered to regenerate it...   \n\n                                                 can  sem_score  \n0  a charity has said it is \"a desperate need\" to...   0.877895  \n1  a man has appeared in court charged with the m...   0.632784  \n2  four people have been charged with aggravated ...   0.610834  \n3  west brom have signed west brom striker david ...   0.743915  \n4  people with type 1 and type 2 diabetes should ...   0.789195  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ref</th>\n      <th>can</th>\n      <th>sem_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>there is a \"chronic\" need for more housing for...</td>\n      <td>a charity has said it is \"a desperate need\" to...</td>\n      <td>0.877895</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a man has appeared in court after firearms, am...</td>\n      <td>a man has appeared in court charged with the m...</td>\n      <td>0.632784</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>four people accused of kidnapping and torturin...</td>\n      <td>four people have been charged with aggravated ...</td>\n      <td>0.610834</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>west brom have appointed nicky hammond as tech...</td>\n      <td>west brom have signed west brom striker david ...</td>\n      <td>0.743915</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>the pancreas can be triggered to regenerate it...</td>\n      <td>people with type 1 and type 2 diabetes should ...</td>\n      <td>0.789195</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":120},{"cell_type":"code","source":"!python3 /kaggle/working/ROUGE-SEM/candidate_summary_classifier.py -lex_score lexical_similarity.csv -sem_score semantic_similarity.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T20:45:58.077686Z","iopub.execute_input":"2025-10-25T20:45:58.077984Z","iopub.status.idle":"2025-10-25T20:46:03.965282Z","shell.execute_reply.started":"2025-10-25T20:45:58.077961Z","shell.execute_reply":"2025-10-25T20:46:03.964491Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":133},{"cell_type":"code","source":"cat_sum = pd.read_csv(\"/kaggle/working/categorized_summary.csv\")\ncat_sum","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T20:46:03.966882Z","iopub.execute_input":"2025-10-25T20:46:03.967196Z","iopub.status.idle":"2025-10-25T20:46:03.981990Z","shell.execute_reply.started":"2025-10-25T20:46:03.967169Z","shell.execute_reply":"2025-10-25T20:46:03.981388Z"}},"outputs":[{"execution_count":134,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                                ref  \\\n0           0  there is a \"chronic\" need for more housing for...   \n1           1  a man has appeared in court after firearms, am...   \n2           2  four people accused of kidnapping and torturin...   \n3           3  west brom have appointed nicky hammond as tech...   \n4           4  the pancreas can be triggered to regenerate it...   \n\n                                                 can  lex_score  sem_score  \\\n0  a charity has said it is \"a desperate need\" to...     26.580   0.877895   \n1  a man has appeared in court charged with the m...     26.164   0.632784   \n2  four people have been charged with aggravated ...     29.418   0.610834   \n3  west brom have signed west brom striker david ...     14.518   0.743915   \n4  people with type 1 and type 2 diabetes should ...     20.418   0.789195   \n\n   category  \n0         2  \n1         2  \n2         2  \n3         2  \n4         2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>ref</th>\n      <th>can</th>\n      <th>lex_score</th>\n      <th>sem_score</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>there is a \"chronic\" need for more housing for...</td>\n      <td>a charity has said it is \"a desperate need\" to...</td>\n      <td>26.580</td>\n      <td>0.877895</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>a man has appeared in court after firearms, am...</td>\n      <td>a man has appeared in court charged with the m...</td>\n      <td>26.164</td>\n      <td>0.632784</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>four people accused of kidnapping and torturin...</td>\n      <td>four people have been charged with aggravated ...</td>\n      <td>29.418</td>\n      <td>0.610834</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>west brom have appointed nicky hammond as tech...</td>\n      <td>west brom have signed west brom striker david ...</td>\n      <td>14.518</td>\n      <td>0.743915</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>the pancreas can be triggered to regenerate it...</td>\n      <td>people with type 1 and type 2 diabetes should ...</td>\n      <td>20.418</td>\n      <td>0.789195</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":134},{"cell_type":"code","source":"%%writefile /kaggle/working/ROUGE-SEM/candidate_summary_classifier.py\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Mar  2 20:53:19 2023\n\n@author: zhangming\n\"\"\"\nimport os\nimport torch\nimport argparse\nfrom scipy.spatial.distance import cosine\nfrom transformers import AutoModel, AutoTokenizer\nimport pandas as pd\nimport tqdm\nimport csv\nimport numpy as np\n\nAlpha_parameter = 0.5\nBeta_parameter = 0.5\n\nparser = argparse.ArgumentParser()\nparser.add_argument('-lex_score', type=str, default=\"lexical_similarity.csv\",\n                    help='candidate file')\nparser.add_argument('-sem_score', type=str, default=\"semantic_similarity.csv\",\n                    help='reference file')\nargs = parser.parse_args()\n\nlex_df = pd.read_csv(args.lex_score)\nlex_score_list = lex_df[\"lex_score\"].tolist()\nreferences = lex_df[\"ref\"].tolist()\ncandidates = lex_df[\"can\"].tolist()\n\nsem_df = pd.read_csv(args.sem_score)\nsem_score_list = sem_df[\"sem_score\"].tolist()    \n\ncategory_list = []\nfor item_lex, item_sem in zip(lex_score_list, sem_score_list):\n    item_lex = item_lex / 100.0 # normalize lexical score\n    if item_lex >= Alpha_parameter and item_sem >= Beta_parameter:\n        category_list.append(0)\n    if item_lex >= Alpha_parameter and item_sem < Beta_parameter:\n        category_list.append(1)\n    if item_lex < Alpha_parameter and item_sem >= Beta_parameter:\n        category_list.append(2)\n    if item_lex < Alpha_parameter and item_sem < Beta_parameter:\n        category_list.append(3)\n\nname = ['ref', 'can', 'lex_score', 'sem_score', 'category']\ntemp = []\ntemp.append(references)\ntemp.append(candidates)\ntemp.append(lex_score_list)\ntemp.append(sem_score_list)\ntemp.append(category_list)\ntemp_df = np.array(temp)\ntemp_df = temp_df.T\ntemp_df = pd.DataFrame(temp_df, columns=name)\ntemp_df.to_csv('categorized_summary.csv', encoding='utf-8')\n            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T20:45:54.037209Z","iopub.execute_input":"2025-10-25T20:45:54.037780Z","iopub.status.idle":"2025-10-25T20:45:54.043887Z","shell.execute_reply.started":"2025-10-25T20:45:54.037754Z","shell.execute_reply":"2025-10-25T20:45:54.043255Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/ROUGE-SEM/candidate_summary_classifier.py\n","output_type":"stream"}],"execution_count":132},{"cell_type":"code","source":"%%writefile /kaggle/working/ROUGE-SEM/calculate_semantic_similarity.py\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Mar  2 20:53:19 2023\n\n@author: zhangming\n\"\"\"\nimport os\nimport torch\nimport argparse\nfrom scipy.spatial.distance import cosine\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nimport pandas as pd\nimport tqdm\nimport csv\n\ndef get_sents_str(file_path):\n    sents = []\n    with open(file_path, 'r', encoding='utf-8') as f:\n        for line in f.readlines():\n            line = line.strip()\n            line = line.lower()\n            sents.append(line)\n    return sents\n\nparser = argparse.ArgumentParser()\nparser.add_argument('-c', type=str, default=\"candidate.txt\",\n                    help='candidate file')\nparser.add_argument('-r', type=str, default=\"reference.txt\",\n                    help='reference file')\nargs = parser.parse_args()\n\nref_path = get_sents_str(args.r)\ncan_path = get_sents_str(args.c)\n    \n# Usa il percorso assoluto per evitare problemi con Hugging Face\nmodel_path = \"/kaggle/working/ROUGE-SEM/model\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n\n# Usa DIRETTAMENTE le liste (BUG CORRETTO)\nref_summary = ref_path  # Questa è già una lista di stringhe\ncan_summary = can_path  # Questa è già una lista di stringhe\n    \n# Tokenize input texts\nref_inputs = tokenizer(ref_summary, padding=True, truncation=True, return_tensors=\"pt\")\n\n# Get the embeddings DALL'ENCODER (non dal modello completo)\nwith torch.no_grad():\n    ref_outputs = model.get_encoder()(**ref_inputs)\n    # Usa last_hidden_state e fai mean pooling\n    ref_embeddings = ref_outputs.last_hidden_state.mean(dim=1)\n    \n# Tokenize candidate texts\ncan_inputs = tokenizer(can_summary, padding=True, truncation=True, return_tensors=\"pt\")\n\nwith torch.no_grad():\n    can_outputs = model.get_encoder()(**can_inputs)\n    # Usa last_hidden_state e fai mean pooling\n    can_embeddings = can_outputs.last_hidden_state.mean(dim=1)\n\n# Calculate cosine similarities\nsimilar_lst = []\nfor i in tqdm.tqdm(range(len(can_embeddings))):\n    cosine_sim_ref_can = 1 - cosine(ref_embeddings[i].numpy(), can_embeddings[i].numpy())\n    similar_lst.append(cosine_sim_ref_can)\n                           \ndata_list = []\nfor a, b, c in zip(ref_summary, can_summary, similar_lst):\n    x = {}\n    x['ref'] = a\n    x['can'] = b\n    x['Sem'] = c\n    data_list.append(x)\n\noutpath = './semantic_similarity.csv'\nwith open(outpath, 'w', newline='', encoding='UTF-8') as f_c_csv:\n    writer = csv.writer(f_c_csv)\n    writer.writerow(['ref', 'can', 'sem_score'])\n    for nl in data_list:\n        writer.writerow(nl.values())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T20:27:39.508202Z","iopub.execute_input":"2025-10-25T20:27:39.508510Z","iopub.status.idle":"2025-10-25T20:27:39.515600Z","shell.execute_reply.started":"2025-10-25T20:27:39.508486Z","shell.execute_reply":"2025-10-25T20:27:39.514962Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/ROUGE-SEM/calculate_semantic_similarity.py\n","output_type":"stream"}],"execution_count":118},{"cell_type":"code","source":"%%writefile /kaggle/working/ROUGE-SEM/calculate_lexical_similarity.py\nimport sys\nimport os\nimport rouge\nimport bert_score\nimport argparse\nimport codecs\nimport nltk\nnltk.download('punkt')\nimport numpy as np\nimport pandas as pd\n\n\nclass Logger(object):\n    def __init__(self, filename=\"Default.log\"):\n        self.terminal = sys.stdout\n        self.log = open(filename, \"a\")\n \n    def write(self, message):\n        self.terminal.write(message)\n        self.log.write(message)\n \n    def flush(self):\n        pass\n\n\ndef prepare_results(metric, p, r, f):\n    return '\\t{}:\\t {:5.2f}\\t {:5.2f}\\t {:5.2f}'.format(metric, 100.0 * p, 100.0 * r,\n                                                                 100.0 * f)\n\n\ndef test_rouge(candidates, references):\n    candidates = [line.strip() for line in candidates]\n    references = [line.strip() for line in references]\n    assert len(candidates) == len(references)\n\n    apply_avg = True\n    apply_best = False\n\n    evaluator = rouge.Rouge(metrics=['rouge-n', 'rouge-l', 'rouge-w'],\n                            max_n=4,\n                            limit_length=True,\n                            length_limit=100,\n                            length_limit_type='words',\n                            apply_avg=apply_avg,\n                            apply_best=apply_best,\n                            alpha=0.5,  # Default F1_score\n                            weight_factor=1.2,\n                            stemming=True)\n\n    all_hypothesis = candidates\n    all_references = references\n\n    scores = evaluator.get_scores(all_hypothesis, all_references)\n#    print(scores)\n\n    rougel = \"\"\n    for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n        if metric in [\"rouge-1\", \"rouge-2\", \"rouge-l\"]:\n    #        print(prepare_results(metric, results['p'], results['r'], results['f']))\n            rougel = rougel + '{:5.2f}'.format(100 * results['f']) + \"-\"\n\n    print(\"ROUGE 1-2-L F:\", rougel)\n    return rougel\n\n\n\ndef get_sents_str(file_path):\n    sents = []\n    with open(file_path, 'r', encoding='utf-8') as f:\n        for line in f.readlines():\n            line = line.strip()\n            line = line.lower()\n            sents.append(line)\n    return sents\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-c', type=str, default=\"candidate.txt\",\n                        help='candidate file')\n    parser.add_argument('-r', type=str, default=\"reference.txt\",\n                        help='reference file')\n    args = parser.parse_args()\n\n    references = get_sents_str(args.r)\n    candidates = get_sents_str(args.c)\n\n    #print(references)\n    sys.stdout = Logger('test_log.txt')\n    \n    print('################### Total #################')\n    print('Rouge')\n    score_total = test_rouge(candidates, references)\n    \n    print('################### Each #################')\n    R1_list = []\n    R2_list = []\n    RL_list = []\n\n    for item_c, item_r in zip(candidates, references):\n        # 01 Rouge score - CORRETTO\n        score_tmp = test_rouge([item_c], [item_r])\n        score_parts = score_tmp.rstrip('-').split('-')  # Rimuovi trattino finale\n        R1_list.append(float(score_parts[0]))\n        R2_list.append(float(score_parts[1]))\n        RL_list.append(float(score_parts[2]))\n    \n    lex_score_list = []\n    for item_R1, item_R2, item_RL in zip(R1_list, R2_list, RL_list):\n        lex_score_temp = 0.3*float(item_R1) + 0.3*float(item_R2) + 0.4*float(item_RL)\n        lex_score_list.append(lex_score_temp)\n\n    # Rouge + Bert \n    name = ['ref', 'can', 'R1', 'R2', 'RL', 'lex_score']\n    temp = []\n    temp.append(references)\n    temp.append(candidates)\n    temp.append(R1_list)\n    temp.append(R2_list)\n    temp.append(RL_list)\n    temp.append(lex_score_list)\n    temp_df = np.array(temp)\n    temp_df = temp_df.T\n    temp_df = pd.DataFrame(temp_df, columns=name)\n    temp_df.to_csv('lexical_similarity.csv', encoding='utf-8')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T20:09:52.786728Z","iopub.execute_input":"2025-10-25T20:09:52.787286Z","iopub.status.idle":"2025-10-25T20:09:52.795484Z","shell.execute_reply.started":"2025-10-25T20:09:52.787262Z","shell.execute_reply":"2025-10-25T20:09:52.794700Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/ROUGE-SEM/calculate_lexical_similarity.py\n","output_type":"stream"}],"execution_count":95}]}